# Google Cloud Dataflow Development Environment

ğŸš€ A comprehensive local development environment for building and testing Apache Beam pipelines with Google Cloud Dataflow.

## ğŸ“‹ Overview

This repository provides a complete setup for developing Apache Beam pipelines locally and deploying them to Google Cloud Dataflow. It includes all necessary configurations, dependencies, and best practices for Dataflow development.

## ğŸ› ï¸ Features

- âœ… **Virtual Environment Setup**: Isolated Python environment with `.venv`
- âœ… **Apache Beam SDK**: Latest stable version with Google Cloud integration
- âœ… **Development Tools**: Pre-configured linting, formatting, and testing
- âœ… **IDE Integration**: VS Code configuration with Python and Cloud extensions
- âœ… **Dependency Management**: Version-locked requirements for reproducibility
- âœ… **Project Structure**: Best practice directory layout
- âœ… **Documentation**: Comprehensive setup and troubleshooting guide

## ğŸ—ï¸ Project Structure

```
dataflow-learning/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ pipelines/                # Dataflow pipelines
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ example_pipeline.py  # Example pipeline
â”‚   â”‚   â””â”€â”€ utils.py             # Utility functions
â”‚   â””â”€â”€ tests/                    # Test files
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ test_example_pipeline.py
â”‚       â””â”€â”€ test_utils.py
â”œâ”€â”€ .venv/                        # Virtual environment
â”œâ”€â”€ .vscode/                      # VS Code configuration
â”‚   â””â”€â”€ settings.json
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ setup.py                      # Package setup
â”œâ”€â”€ .env.example                  # Environment variables template
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ Google_Cloud_Dataflow_Local_Setup_Guide.md  # Setup guide
â””â”€â”€ README.md                     # This file
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+ (recommended 3.11)
- Google Cloud account with billing enabled
- Git installed

### Setup

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd dataflow-learning
   ```

2. **Create and activate virtual environment**
   ```bash
   python -m venv .venv
   .venv\Scripts\activate  # Windows
   # source .venv/bin/activate  # macOS/Linux
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure Google Cloud**
   ```bash
   gcloud init
   gcloud auth application-default login
   ```

5. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your project details
   ```

### Run Your First Pipeline

```bash
# Local execution
python src/pipelines/example_pipeline.py --runner DirectRunner

# Cloud execution
python src/pipelines/example_pipeline.py \
    --runner DataflowRunner \
    --project YOUR_PROJECT_ID \
    --region us-central1 \
    --temp_location gs://YOUR_BUCKET/temp/
```

## ğŸ“š Documentation

- ğŸ“– [Complete Setup Guide](./Google_Cloud_Dataflow_Local_Setup_Guide.md)
- ğŸ”§ [Configuration Guide](#configuration)
- ğŸ§ª [Testing Guide](#testing)
- ğŸš€ [Deployment Guide](#deployment)

## ğŸ› ï¸ Development

### Code Quality Tools

- **Black**: Code formatting
- **Flake8**: Linting
- **MyPy**: Type checking
- **Pytest**: Testing framework

### Common Commands

```bash
# Format code
black src/

# Lint code
flake8 src/

# Type check
mypy src/

# Run tests
pytest src/tests/

# Install development dependencies
pip install -r requirements.txt
```

## ğŸ³ Docker Support

Optional Docker configuration for containerized development:

```bash
# Build Docker image
docker build -t dataflow-dev .

# Run container
docker run -it dataflow-dev
```

## ğŸŒ Cloud Integration

### Required Google Cloud APIs

- Dataflow API
- Cloud Storage API
- Cloud Logging API
- Cloud Monitoring API

### Service Account Setup

```bash
# Create service account
gcloud iam service-accounts create dataflow-developer

# Grant necessary roles
gcloud projects add-iam-policy-binding YOUR_PROJECT_ID \
    --member="serviceAccount:dataflow-developer@YOUR_PROJECT_ID.iam.gserviceaccount.com" \
    --role="roles/dataflow.developer"
```

## ğŸ§ª Testing

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src

# Run specific test file
pytest src/tests/test_example_pipeline.py
```

### Test Structure

```
src/tests/
â”œâ”€â”€ test_example_pipeline.py  # Pipeline integration tests
â”œâ”€â”€ test_utils.py            # Utility function tests
â””â”€â”€ fixtures/                # Test data files
```

## ğŸ“Š Monitoring

### Local Monitoring

- Pipeline logs via console output
- Local file system for intermediate results

### Cloud Monitoring

- Google Cloud Console: Dataflow Jobs
- Cloud Logging: Structured logs
- Cloud Monitoring: Metrics and alerts

## ğŸ”§ Configuration

### Environment Variables

Create `.env` file from `.env.example`:

```env
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_CLOUD_REGION=us-central1
DATAFLOW_TEMP_LOCATION=gs://your-bucket/temp/
DATAFLOW_STAGING_LOCATION=gs://your-bucket/staging/
```

### VS Code Settings

The `.vscode/settings.json` file provides:
- Python interpreter configuration
- Linting and formatting settings
- Test discovery configuration
- Google Cloud integration

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Workflow

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate

# Install development dependencies
pip install -r requirements.txt

# Run pre-commit checks
black src/
flake8 src/
mypy src/
pytest src/tests/
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- ğŸ“– [Google Cloud Dataflow Documentation](https://cloud.google.com/dataflow/docs)
- ğŸ“– [Apache Beam Documentation](https://beam.apache.org/documentation/)
- ğŸ› [Issues](https://github.com/your-username/dataflow-learning/issues)
- ğŸ’¬ [Discussions](https://github.com/your-username/dataflow-learning/discussions)

## ğŸ™ Acknowledgments

- [Apache Beam](https://beam.apache.org/) - Unified programming model
- [Google Cloud Dataflow](https://cloud.google.com/dataflow) - Managed service
- [VS Code](https://code.visualstudio.com/) - Development environment

---

**Happy Dataflow Development! ğŸ‰**

Built with â¤ï¸ for the Apache Beam and Google Cloud community.
